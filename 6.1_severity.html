<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>6.1 Power centralization and unfair distribution of benefits - Business as usual Scenario</title>
    <link href="https://fonts.googleapis.com/css2?family=Figtree:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Figtree', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background-color: #ffffff;
            color: #000000;
            line-height: 1.3;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;
        }

        h1 {
            text-align: center;
            margin-bottom: 8px;
            color: #000000;
            font-weight: 600;
            font-size: 18px;
        }

        .selection-title {
            text-align: center;
            font-size: 14px;
            font-weight: 600;
            color: #666666;
            margin-bottom: 10px;
        }

        .nav-pills {
            display: flex;
            flex-wrap: wrap;
            gap: 4px;
            margin-bottom: 15px;
            justify-content: center;
        }

        .nav-pill {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 25px;
            padding: 12px 20px;
            cursor: pointer;
            font-family: 'Figtree', sans-serif;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s ease;
            color: #000000;
        }

        .nav-pill:hover {
            background: #e9ecef;
            border-color: #000000;
        }

        .nav-pill.active {
            background: #a32035;
            color: white;
            border-color: #a32035;
        }

        .tab-section {
            display: none;
        }

        .tab-section.active {
            display: block;
        }

        .content-box {
            background: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 15px;
        }

        .criteria-header {
            font-size: 15px;
            font-weight: 600;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid #a32035;
            color: #a32035;
        }

        .summary-section {
            margin-bottom: 20px;
        }

        .summary-text {
            margin-bottom: 15px;
            font-weight: 500;
            color: #000000;
            font-size: 15px;
        }

        .quote-details {
            margin-top: 15px;
        }

        .quote-toggle {
            cursor: pointer;
            color: #000000;
            font-weight: 500;
            font-size: 14px;
            padding: 8px 0;
            border-bottom: 1px dotted #a32035;
            display: inline-block;
        }

        .quote-toggle:hover {
            color: #333333;
        }

        .quote-list {
            margin-top: 15px;
            padding-left: 20px;
        }

        .quote-list li {
            margin-bottom: 12px;
            font-size: 12px;
            line-height: 1.3;
            color: #000000;
        }

        @media (max-width: 768px) {
            .nav-pill {
                font-size: 10px;
                padding: 4px 8px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>6.1 Power centralization and unfair distribution of benefits - Business as usual Scenario</h1>

        <div class="selection-title">Select a category:</div>
        <div class="nav-pills">
            <button class="nav-pill active" data-target="reasoning">
                Reasoning
            </button>
            <button class="nav-pill" data-target="other">
                Other
            </button>
        </div>

        <div class="content-sections">
            <div class="tab-section active" id="reasoning">
                <div class="content-box">
                    <h3 class="criteria-header">Reasoning</h3>
                    <div class="summary-section">
                        <p class="summary-text"><strong>AI-Generated Summary of Expert Comments:</strong> [editor's note: due to the volume of expert comments, this AI-generated summary may be insufficient/misleading]. Main harms identified include dramatic market concentration with top 10 S&P 500 companies now representing 38% (up from roughly 10% five years ago), widening global inequalities through uneven access to AI capabilities and infrastructure, equity wipeouts and forced sales of startups worth $100 million to $10 billion, and sinking relative value of labor as automation spreads. Under Business as Usual, experts expect substantial to severe harm as economic and political influence concentrates within a small number of enterprises and nations, with some projecting the accelerating trend could leave all other companies representing only a quarter of market indices. Under Pragmatic Mitigations, open-access ecosystems, inclusive policy, and capability building can reduce civilization-level harm and shift distribution toward minor or substantial levels. However, multiple experts emphasize that historical precedent suggests governments only intervene enough to avoid coups or riots but not enough to address regulatory capture, that antitrust moves slowly so probabilities remain non-trivial, that this would require regulatory intervention of unprecedented scale, and that avoiding concentration through open-sourcing could paradoxically increase other catastrophic risks like bioterrorism.</p>

                        <details class="quote-details">
                            <summary class="quote-toggle">See all expert comments (10)</summary>
                            <ul class="quote-list">
                                <li>"The 5 year time horizon is somewhat frustrating, given that I think most harm is likely to materialize later (even though key leverage points for avoiding those harms are likely within the next 5 years). I believe the delay in materialization is largely mediated by the rate at which the technology will diffuse through the economy.

Anyhow, re pragmatic mitigations: I'm not sure what these entail, but if historical precedent is anything to go by, I believe they will only mitigate the most severe outcomes, but largely leave substantial harm to propagate. E.g. presumably if power concentration in a single private firm truly threatened the US government's power, the latter would react to protect its prerogatives, avoiding a coup/authoritarian takeover from that direction. Similarly, if unemployment spiked, the government will likely start sending pay cheques or funding retraining programs enough to quell riots and institutional breakdown, but not enough to fix e.g. significant regulatory capture, lobbying and disenfranchisement through campaign finance loopholes.

I'll also flag that avoiding power concentration (by e.g. encouraging open-sourcing AI systems) could also increase the risk of e.g. rogue bio-terrorism, hence my higher catastrophic prediction under the "Pragmatic mitigations" condition."</li>
                                <li>"AI economic and political influence is likely to concentrate within a small number of enterprises and nations (look at the planned spend), widening global and social inequalities. Substantial to severe harms are most probable as access to AI capabilities, data, and infrastructure remains uneven, leading to economic dependency and loss of competitiveness across developing markets. Catastrophic outcomes, though less probable, could occur if entrenched AI monopolies distort governance or suppress equitable innovation. With pragmatic mitigations-such as open-access AI ecosystems, inclusive policy frameworks, transparent value-sharing models, and investment in local capability building risks decline notably. Most harms shift to minor or substantial, as balanced regulation and public-private collaboration help ensure fairer distribution of AI benefits and reduced concentration of power"</li>
                                <li>"I believe substantial harm is likely even at our current level of AI development - it's really a question of adoption, in that it still takes time for bad or careless actors to adopt at scale and generate resulting harm at scale."</li>
                                <li>"pragmatic interventions can reduce the chance of systemic or civilization-level harm."</li>
                                <li>"Some studies have disagreed on the economic impact of AI to date, with productivity and labor data being inconclusive.  However there is a figure which is fairly conclusive, which is the proportion of the S&amp;P 500 represented by just the top 10 companies which are now mainly AI companies.  Those companies have seen their proportion roughly quadruple within 5 years, and now represent 38%.  This demonstrates centralisation is a current state phenomena.  It may just be a bubble and revert to the mean,  but should the accelerating trend continue for another 5 years, then all the other companies put together would only be a quarter of the index. 

It is unlikely small scale pragmatic tinkering would resolve that level of market distortion. It would require a regulatory intervention of unprecedented scale."</li>
                                <li>"This is also a completely reversible risk that can be altogether eliminated, but is just not in the interest of the markets or colonial extraction, so mitigations against this are likely not going to be highly incentivized"</li>
                                <li>"Severe tail reflects consolidation risk. Incumbents can use compute and distribution chokepoints, exclusive supply, bundling, standards capture, and defensive IP suits to squeeze new labs. That dynamic could shutter or force distressed sales of high-valuation startups (for example Safe Superintelligence Inc. or Thinking Machines Lab). Resulting equity wipeouts and creditor losses plausibly land in the $100M $10B band, which fits, severe.Pragmatic mitigations target safety, not competition. Antitrust moves slowly, so probabilities stay non-trivial over five years."</li>
                                <li>"We have historically been very poor at controlling for the power- and wealth-centralizing effects of technological innovations. AI is posed to be an extreme example: very few people, societally speaking, are required to train systems which hold the promise of automating vast swathes of what currently is done by humans. If the relative value of labor sinks accordingly, because e.g. diffusion is reasonably easy or fast including to physical domains, it seems likely that power centralization follows. It seems the expect would be all the worse for those countries without frontier systems. Mitigations may include all sorts of ownership structure, labor market, or economic interventions in these firms and beyond; there is reasonable grounds to believe these would be effective."</li>
                                <li>"again i put 'minor' as i feel the tech itself will not have a profound impact on power etc beyond what any tech would afford."</li>
                                <li>"Likely to be some centralisation and market distortion, which will cost at least $100M aggregated across the market, likely much more"</li>
                            </ul>
                        </details>
                    </div>
                </div>
            </div>

            <div class="tab-section" id="other">
                <div class="content-box">
                    <h3 class="criteria-header">Other</h3>
                    <div class="summary-section">
                        <p class="summary-text"><strong>AI-Generated Summary of Expert Comments:</strong> One expert commented: "In this category, I was mostly considering potential wars (cyber warfare and traditional warfare). "</p>

                        <details class="quote-details">
                            <summary class="quote-toggle">See all expert comments (1)</summary>
                            <ul class="quote-list">
                                <li>"In this category, I was mostly considering potential wars (cyber warfare and traditional warfare)."</li>
                            </ul>
                        </details>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const pills = document.querySelectorAll('.nav-pill');
            const sections = document.querySelectorAll('.tab-section');

            pills.forEach(pill => {
                pill.addEventListener('click', function() {
                    pills.forEach(p => p.classList.remove('active'));
                    sections.forEach(s => s.classList.remove('active'));

                    this.classList.add('active');

                    const targetId = this.getAttribute('data-target');
                    const targetSection = document.getElementById(targetId);
                    if (targetSection) {
                        targetSection.classList.add('active');
                    }
                });
            });
        });
    </script>
</body>
</html>
