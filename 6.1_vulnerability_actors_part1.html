<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>6.1 Power centralization and unfair distribution of benefits - Vulnerability (Actors)</title>
    <link href="https://fonts.googleapis.com/css2?family=Figtree:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Figtree', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background-color: #ffffff;
            color: #000000;
            line-height: 1.3;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;
        }

        h1 {
            text-align: center;
            margin-bottom: 8px;
            color: #000000;
            font-weight: 600;
            font-size: 18px;
        }

        .selection-title {
            text-align: center;
            font-size: 14px;
            font-weight: 600;
            color: #666666;
            margin-bottom: 10px;
        }

        .nav-pills {
            display: flex;
            flex-wrap: wrap;
            gap: 4px;
            margin-bottom: 15px;
            justify-content: center;
        }

        .nav-pill {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 25px;
            padding: 12px 20px;
            cursor: pointer;
            font-family: 'Figtree', sans-serif;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s ease;
            color: #000000;
        }

        .nav-pill:hover {
            background: #e9ecef;
            border-color: #000000;
        }

        .nav-pill.active {
            background: #000000;
            color: white;
            border-color: #000000;
        }

        .entity-section {
            display: none;
        }

        .entity-section.active {
            display: block;
        }

        .content-grid {
            display: flex;
            width: 100%;
            gap: 4px;
        }

        .content-column {
            background: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;
        }

        .criteria-header {
            font-size: 12px;
            font-weight: 600;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid;
        }

        .criteria-header.higher {
            color: #FF0000;
            border-bottom-color: #FF0000;
        }

        .criteria-header.lower {
            color: #2E5C8A;
            border-bottom-color: #2E5C8A;
        }

        .summary-section {
            margin-bottom: 20px;
        }

        .summary-text {
            margin-bottom: 15px;
            font-weight: 500;
            color: #000000;
            font-size: 15px;
        }

        .quote-details {
            margin-top: 15px;
        }

        .quote-toggle {
            cursor: pointer;
            color: #000000;
            font-weight: 500;
            font-size: 16px;
            background-color: #ffff00;
            padding: 10px 15px;
            border-radius: 4px;
            display: inline-block;
        }

        .quote-toggle:hover {
            color: #333333;
        }

        .quote-list {
            margin-top: 15px;
            padding-left: 20px;
        }

        .quote-list li {
            margin-bottom: 12px;
            font-size: 16px;
            padding: 10px 15px;
            line-height: 1.3;
            color: #000000;
        }

        @media (max-width: 768px) {
            .content-grid {
                gap: 4px;
            }

            .selection-title {
                text-align: center;
                font-size: 14px;
                font-weight: 600;
                color: #666666;
                margin-bottom: 10px;
            }

            .nav-pills {
                justify-content: flex-start;
            }

            .nav-pill {
                font-size: 16px;
                padding: 4px 8px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>6.1 Power centralization and unfair distribution of benefits - Vulnerability (Actors)</h1>

        <div class="selection-title">Select a actor:</div>
                <div class="nav-pills">
            <button class="nav-pill active" data-target="AIDeveloperGeneralpurposeAI">
                AI Developer (General-purpose AI)
            </button>
            <button class="nav-pill" data-target="AIDeployer">
                AI Deployer
            </button>
            <button class="nav-pill" data-target="AIGovernanceActor">
                AI Governance Actor
            </button>
            <button class="nav-pill" data-target="AIUser">
                AI User
            </button>
        </div>

                <div class="content-sections">
<div class="entity-section active" id="AIDeveloperGeneralpurposeAI">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> There will likely be both winners and losers in this category - leading AI developers are minimally vulnerable as they'll be benefitting from power concentration, but smaller AI developers will be highly vulnerable as they can't compete with larger developers, warranting a moderate vulnerability rating overall. In the long term, even companies that own the best AIs may lose to dictatorships/juntas formed by their own leadership plus political leaders</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"I agree with the larger group that leading AI developers are minimally vulnerable to power concentration, as they will be the ones benefitting. However, there will likely be smaller AI developers that are highly vulnerable given that they can't compete with larger developers. Therefore, I listed AI developers as moderately vulnerable. In short, there will be both winners and losers in this category."</li>                    <li>"I think people aren't thinking far enough ahead. In the short term, the stakeholders and infra providers and so forth will lose out to the companies that own the best AIs. But in the long term, those companies themselves will lose to dictatorships/juntas formed by their own leadership + the POTUS etc., or at least, this is a very plausible outcome and must be prevented by active corporate governance to keep shareholders in meaningful control through the singularity."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> Developers and infrastructure providers are no more vulnerable than with any other technology. Even oligopolistic actors have something to fear from complete monopoly—if power centralizes completely, only one wins and the others lose out. One expert revised their rating from extremely to moderately vulnerable after reconsidering, noting that while developers have high exposure since their work creates systems that may centralize power, their sensitivity to harm is considerably lower than other actors. Many developers, particularly at large tech companies, are positioned to be beneficiaries rather than victims—they gain job security, increased compensation, influence over standards, and access to resources that smaller competitors cannot match. The unfair distribution of benefits largely flows toward these developers rather than away from them.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (3)</summary>
                <ul class="quote-list">
                    <li>"I originally had the large actors at "not at all impacted" but if power centralises completely, only one of them wins and the others lose out. So even monopolistic oligarchs have something to fear from complete monopoly."</li>                    <li>"For AI Developers (General-purpose AI), after reconsidering, I am revising my rating from extremely vulnerable to moderately vulnerable regarding power centralization and unfair distribution of benefits.
While AI developers have high exposure to this risk since their work directly creates the systems that may centralize power, their sensitivity to harm is considerably lower than other actors. In fact, many AI developers, particularly those at large technology companies, are positioned to be beneficiaries rather than victims of power centralization. As AI systems concentrate capabilities and market power in a few dominant organizations, developers at these firms gain significant advantages: enhanced job security, increased compensation, greater influence over industry standards, and access to computational resources and data that smaller competitors cannot match. The "unfair distribution of benefits" largely flows toward these developers and their employers rather than away from them.
The moderately vulnerable rating reflects that some segments of the AI developer community may face indirect harms such as independent researchers losing competitive viability, developers at smaller firms facing market exclusion, or even individuals experiencing reputational risks from association with concentrations of power. However, as a group, AI developers are substantially less vulnerable to harm from this risk compared to downstream users, affected communities, or competitors locked out of increasingly concentrated AI markets."</li>                    <li>"Simply put I feel it is the use of AI that is extermely vulnerable. developers of infrastructure providers I feel are no more vulnerable than with any tech."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
<div class="entity-section" id="AIDeployer">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> One expert commented: "I originally had the large actors at 'not at all impacted' but if power centralises completely, only one of them wins and the others lose out. So even monopolistic oligarchs have something to fear from complete monopoly."</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"I originally had the large actors at "not at all impacted" but if power centralises completely, only one of them wins and the others lose out. So even monopolistic oligarchs have something to fear from complete monopoly."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
<div class="entity-section" id="AIGovernanceActor">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> AI governance actors are dependent on AI developers and deployers for technology solutions and are therefore extremely vulnerable to power centralization and unfair distribution of benefits, especially in domains of public administration and national security. They depend on a small number of dominant providers, increasing their vulnerability.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"AI Governance Actors and AI Developer (Specialized AI): highly vulnerable because they depend on small number of dominant providers."</li>                    <li>"AI governance actors are dependent on AI developers and deployers for technology solutions and are therefore extremely vulnerable to power centralization and unfair distribution of benefits, especially in the domains of public administration and national security."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> Some governance actors will benefit from power centralization—if a "regulatory market" emerges (e.g., insurers creating standards/ratings for developers), likely only one or a few standards/ratings will win out due to network effects. Lack of trust is slowing AI adoption for enterprise, so certification/assurance services are in high demand, but few companies in that market will survive.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"Quite surprised by how vulnerable others rated AI Governance actor: updating upward toward moderate. However, I think it's not being noted that some Governance Actors will benefit from power centralization (e.g. if we see a "regulatory market" emerge of e.g. insurers creating standards/ratings for developers to follow/be scored against, it's likely only one or a few standards/ratings will win out, due to network effects). Lack of trust is slowing AI adoption for entreprise, so such certification/assurance services are in high demand, but few companies in that market will survive. Note how few credit rating agencies there are (S&amp;P, Moody's, and Fitch make up over 90% of market)."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
<div class="entity-section" id="AIUser">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> One expert commented: "Simply put I feel it is the use of AI that is extermely vulnerable. developers of infrastructure providers I feel are no more vulnerable than with any tech."</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"Simply put I feel it is the use of AI that is extermely vulnerable. developers of infrastructure providers I feel are no more vulnerable than with any tech."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIDeveloperSpecializedAI">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> One expert commented: "highly vulnerable because they depend on small number of dominant providers."</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"AI Governance Actors and AI Developer (Specialized AI): highly vulnerable because they depend on small number of dominant providers."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIDeployer">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> One expert commented: "I originally had the large actors at 'not at all impacted' but if power centralises completely, only one of them wins and the others lose out. So even monopolistic oligarchs have something to fear from complete monopoly."</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"I originally had the large actors at "not at all impacted" but if power centralises completely, only one of them wins and the others lose out. So even monopolistic oligarchs have something to fear from complete monopoly."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIInfrastructureProvider">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> One expert commented: "I actually think infrastructure providers and others who are not typically vulnerable may be so here. They are highly wrapped up in geopolitics and power conflicts, which can lead to dramatic changes in their activities, revenue, regulations, controls, etc."</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"I actually think infrastructure providers and others who are not typically vulnerable may be so here. They are highly wrapped up in geopolitics and power conflicts, which can lead to dramatic changes in their activities, revenue, regulations, controls, etc."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> Even oligopolistic actors have something to fear from complete monopoly—if power centralizes completely, only one wins and the others lose out.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"I originally had the large actors at "not at all impacted" but if power centralises completely, only one of them wins and the others lose out. So even monopolistic oligarchs have something to fear from complete monopoly."</li>                    <li>"Simply put I feel it is the use of AI that is extermely vulnerable. developers of infrastructure providers I feel are no more vulnerable than with any tech."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIUser">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> One expert commented: "Simply put I feel it is the use of AI that is extermely vulnerable. developers of infrastructure providers I feel are no more vulnerable than with any tech."</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"Simply put I feel it is the use of AI that is extermely vulnerable. developers of infrastructure providers I feel are no more vulnerable than with any tech."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AffectedStakeholder">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> The global south is incredibly vulnerable to centralization of AI resources in the global north. This enables global north stakeholders to advance their AI infrastructure, AI-based decision-making, and AI systems to react and respond much faster than those without access to that resourcing, creating an economic, digital, and AI-based divide. The category most badly affected will be those without access to AI tools, which is partly but not completely captured by "affected stakeholder."</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"The global south is incredibly vulnerable to the centralization of AI resources in the global north. This enables global north stakeholders to advance their AI infrastructure, AI-based decision making, and AI systems to react and respond much faster than those without access to that resourcing-- thus creating an economic, digital, and AI-based divide."</li>                    <li>"I remain confident in my assignments. I believe the category who will most badly be affected are those without access to AI tools, which is partly but not completely captured by' affected stakeholder'."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIGovernanceActor">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> AI governance actors are dependent on AI developers and deployers for technology solutions and are therefore extremely vulnerable to power centralization and unfair distribution of benefits, especially in domains of public administration and national security. They depend on a small number of dominant providers, increasing their vulnerability.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"AI Governance Actors and AI Developer (Specialized AI): highly vulnerable because they depend on small number of dominant providers."</li>                    <li>"AI governance actors are dependent on AI developers and deployers for technology solutions and are therefore extremely vulnerable to power centralization and unfair distribution of benefits, especially in the domains of public administration and national security."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary:</strong> Some governance actors will benefit from power centralization—if a "regulatory market" emerges (e.g., insurers creating standards/ratings for developers), likely only one or a few standards/ratings will win out due to network effects. Lack of trust is slowing AI adoption for enterprise, so certification/assurance services are in high demand, but few companies in that market will survive.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"Quite surprised by how vulnerable others rated AI Governance actor: updating upward toward moderate. However, I think it's not being noted that some Governance Actors will benefit from power centralization (e.g. if we see a "regulatory market" emerge of e.g. insurers creating standards/ratings for developers to follow/be scored against, it's likely only one or a few standards/ratings will win out, due to network effects). Lack of trust is slowing AI adoption for entreprise, so such certification/assurance services are in high demand, but few companies in that market will survive. Note how few credit rating agencies there are (S&amp;P, Moody's, and Fitch make up over 90% of market)."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const pills = document.querySelectorAll('.nav-pill');
            const sections = document.querySelectorAll('.entity-section');

            pills.forEach(pill => {
                pill.addEventListener('click', function() {
                    pills.forEach(p => p.classList.remove('active'));
                    sections.forEach(s => s.classList.remove('active'));

                    this.classList.add('active');

                    const targetId = this.getAttribute('data-target');
                    const targetSection = document.getElementById(targetId);
                    if (targetSection) {
                        targetSection.classList.add('active');
                    }
                });
            });
        });
    </script>
</body>
</html>
