<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3.2 False or misleading information - Business as usual Scenario</title>
    <link href="https://fonts.googleapis.com/css2?family=Figtree:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Figtree', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background-color: #ffffff;
            color: #000000;
            line-height: 1.3;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;
        }

        h1 {
            text-align: center;
            margin-bottom: 8px;
            color: #000000;
            font-weight: 600;
            font-size: 18px;
        }

        .selection-title {
            text-align: center;
            font-size: 14px;
            font-weight: 600;
            color: #666666;
            margin-bottom: 10px;
        }

        .nav-pills {
            display: flex;
            flex-wrap: wrap;
            gap: 4px;
            margin-bottom: 15px;
            justify-content: center;
        }

        .nav-pill {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 25px;
            padding: 12px 20px;
            cursor: pointer;
            font-family: 'Figtree', sans-serif;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s ease;
            color: #000000;
        }

        .nav-pill:hover {
            background: #e9ecef;
            border-color: #000000;
        }

        .nav-pill.active {
            background: #a32035;
            color: white;
            border-color: #a32035;
        }

        .tab-section {
            display: none;
        }

        .tab-section.active {
            display: block;
        }

        .content-box {
            background: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 15px;
            margin-bottom: 15px;
        }

        .criteria-header {
            font-size: 15px;
            font-weight: 600;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid #a32035;
            color: #a32035;
        }

        .summary-section {
            margin-bottom: 20px;
        }

        .summary-text {
            margin-bottom: 15px;
            font-weight: 500;
            color: #000000;
            font-size: 15px;
        }

        .quote-details {
            margin-top: 15px;
        }

        .quote-toggle {
            cursor: pointer;
            color: #000000;
            font-weight: 500;
            font-size: 16px;
            background-color: #ffff00;
            padding: 10px 15px;
            border-radius: 4px;
            display: inline-block;
        }

        .quote-toggle:hover {
            color: #333333;
        }

        .quote-list {
            margin-top: 15px;
            padding-left: 20px;
        }

        .quote-list li {
            margin-bottom: 12px;
            font-size: 12px;
            line-height: 1.3;
            color: #000000;
        }

        @media (max-width: 768px) {
            .nav-pill {
                font-size: 16px;
            
            padding: 10px 15px;
            
            
                padding: 4px 8px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>3.2 False or misleading information - Business as usual Scenario</h1>

        <div class="selection-title">Select a category:</div>
        <div class="nav-pills">
            <button class="nav-pill active" data-target="reasoning">
                Reasoning
            </button>
            <button class="nav-pill" data-target="other">
                Other
            </button>
        </div>

        <div class="content-sections">
            <div class="tab-section active" id="reasoning">
                <div class="content-box">
                    <h3 class="criteria-header">Reasoning</h3>
                    <div class="summary-section">
                        <p class="summary-text"><strong>AI-Generated Summary of Expert Comments:</strong> Harms identified include financial losses from scams (already many billions annually), injury/death from harmful LLM advice, ethnic violence incited by fake news, election interference, market manipulation, and trade wars triggered by viral misinformation, with existing impacts documented in COVID misinformation deaths and governments using false information to maintain power and advance wars and genocide. 
Under Business as Usual, experts expect higher harm as generative model capabilities outpace moderation and detection tools, with competition driving speed over safety and no realistic state incentives to prevent harms that fuel regimes. 
Under Pragmatic Mitigations including provenance tagging, watermarking, trusted content frameworks, and coordinated oversight, views diverge sharply on effectiveness, with some experts seeing reduced likelihood of the most severe outcomes through joint industry-government response mechanisms while others argue mitigations do not meaningfully move the needle. 
One expert notes a paradox where pragmatic mitigations might reduce most risks but slightly increase probability of catastrophic harm by increasing reliance on still-unreliable systems. Several experts express skepticism that any pragmatically cost-effective intervention could contain global costs given the scale of existing harms and the ease with which single viral posts can trigger trillion-dollar consequences.</p>

                        <details class="quote-details">
                            <summary class="quote-toggle">See all expert comments (9)</summary>
                            <ul class="quote-list">
                                <li>"Without strong content authenticity frameworks, AI-driven misinformation and synthetic media are expected to proliferate, influencing elections, markets, and social trust. Under business as usual, substantial to severe harms are most likely, as existing moderation and detection tools lag behind generative model capabilities. Catastrophic harm, while less probable, could occur if widespread misinformation erodes democratic stability or incites violence. With pragmatic mitigations such as provenance tagging, watermarking, trusted content frameworks, and coordinated regulatory oversight, the likelihood of severe or catastrophic outcomes decreases sharply. Most harms become minor to substantial, limited to localized or short-lived disinformation incidents that can be detected and corrected through joint industry government response mechanisms."</li>
                                <li>"I do not think "pragmatic mitigations" meaningfully move the needle on risk likelihoods."</li>
                                <li>"In the Business as Usual scenario: Substantial harm (35%) means large organizations suffer significant financial harm or loss of public trust due to systematic misinformation.

Under the "Pragmatic Mitigations" scenario: Negligible and Minor harm (20% and 35%) and  Severe and Catastrophic harm (15% and 5%) reflect the significant reduction, but still acknowledge a residual risk of systemic or catastrophic harms."</li>
                                <li>"I think that even under rigorous controls and mitigations, false and misleading information is highly likely to result in more than $1m in damages (e.g. through successful scams). Thatâ€™s just a fact we need to prepare ourselves for. It is also likely to result in more than 1 death. For instance, in cases like ethnically fragmented societies where the slightest bit of fake news can incite widespread pogroms and riots."</li>
                                <li>"Just in Australia, scams are already in the vicinity of $10B a year, and AI adoption among scammers is rife.  Globally the figure is far far higher, well above the catastrophic $20B level.    Consider the global cost of misinformation during COVID, or the impacts on global trade of misinformation in the current political climate.  A single viral AI generated social media post about a countries trade surplus or deficit can result in tarrifs worth trillions of dollars.  

I struggle to think of an intervention which is both pragmatically cost effective, and capable of addressing the scale of this issue.  If you took all the money in the world and tried to stop AI misinfo, I'm not sure anyone could keep it below $100B in 5 years"</li>
                                <li>"False and misleading information is actively keeping fascist governments in power and mongering war and genocide. There is no realistic chance that states will build sufficient incentives to prevent the very things that fuels them, so why would companies mitigate for these harms, even if it is feasible"</li>
                                <li>"The number of suicides that have already occurred, harmful advice being provided by LLMs, etc. is already monumental. Left unmitigated, these will likely increase as more players enter market and compete based on speed instead of on safety."</li>
                                <li>"Clearly business as usual should not be the norm as AI systems do put out out false and misleading information. Even with pragmatic mitigations there will be some harm done if regulations and enforcement do not catch up"</li>
                                <li>"Pragmatic mitigations are likely to reduce impact, but would also have an unlikely but significant tail impact of increasing reliance on still-unreliable systems, making worst-case events more plausible. (Therefore, mostly lower risk, but slight increases to probability of severe/catastrophic harm.)"</li>
                            </ul>
                        </details>
                    </div>
                </div>
            </div>

            <div class="tab-section" id="other">
                <div class="content-box">
                    <h3 class="criteria-header">Other</h3>
                    <div class="summary-section">
                        <p class="summary-text"><strong>AI-Generated Summary of Expert Comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const pills = document.querySelectorAll('.nav-pill');
            const sections = document.querySelectorAll('.tab-section');

            pills.forEach(pill => {
                pill.addEventListener('click', function() {
                    pills.forEach(p => p.classList.remove('active'));
                    sections.forEach(s => s.classList.remove('active'));

                    this.classList.add('active');

                    const targetId = this.getAttribute('data-target');
                    const targetSection = document.getElementById(targetId);
                    if (targetSection) {
                        targetSection.classList.add('active');
                    }
                });
            });
        });
    </script>
</body>
</html>
