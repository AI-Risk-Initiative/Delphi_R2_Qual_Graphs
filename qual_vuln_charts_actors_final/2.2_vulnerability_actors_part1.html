<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>2.2 AI system security vulnerabilities and attacks - Vulnerability (Actors) - Part 1</title>
    <link href="https://fonts.googleapis.com/css2?family=Figtree:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Figtree', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background-color: #ffffff;
            color: #000000;
            line-height: 1.3;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;
        }

        h1 {
            text-align: center;
            margin-bottom: 8px;
            color: #000000;
            font-weight: 600;
            font-size: 18px;
        }

        .selection-title {
            text-align: center;
            font-size: 14px;
            font-weight: 600;
            color: #666666;
            margin-bottom: 10px;
        }

        .nav-pills {
            display: flex;
            flex-wrap: wrap;
            gap: 4px;
            margin-bottom: 15px;
            justify-content: center;
        }

        .nav-pill {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 25px;
            padding: 12px 20px;
            cursor: pointer;
            font-family: 'Figtree', sans-serif;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s ease;
            color: #000000;
        }

        .nav-pill:hover {
            background: #e9ecef;
            border-color: #000000;
        }

        .nav-pill.active {
            background: #000000;
            color: white;
            border-color: #000000;
        }

        .entity-section {
            display: none;
        }

        .entity-section.active {
            display: block;
        }

        .content-grid {
            display: flex;
            width: 100%;
            gap: 4px;
        }

        .content-column {
            background: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;
        }

        .criteria-header {
            font-size: 12px;
            font-weight: 600;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid;
        }

        .criteria-header.higher {
            color: #FF0000;
            border-bottom-color: #FF0000;
        }

        .criteria-header.lower {
            color: #2E5C8A;
            border-bottom-color: #2E5C8A;
        }

        .summary-section {
            margin-bottom: 20px;
        }

        .summary-text {
            margin-bottom: 15px;
            font-weight: 500;
            color: #000000;
            font-size: 15px;
        }

        .quote-details {
            margin-top: 15px;
        }

        .quote-toggle {
            cursor: pointer;
            color: #000000;
            font-weight: 500;
            font-size: 10px;
            padding: 8px 0;
            border-bottom: 1px dotted #000000;
            display: inline-block;
        }

        .quote-toggle:hover {
            color: #333333;
        }

        .quote-list {
            margin-top: 15px;
            padding-left: 20px;
        }

        .quote-list li {
            margin-bottom: 12px;
            font-size: 10px;
            line-height: 1.3;
            color: #000000;
        }

        @media (max-width: 768px) {
            .content-grid {
                gap: 4px;
            }

            .selection-title {
                text-align: center;
                font-size: 14px;
                font-weight: 600;
                color: #666666;
                margin-bottom: 10px;
            }

            .nav-pills {
                justify-content: flex-start;
            }

            .nav-pill {
                font-size: 10px;
                padding: 4px 8px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>2.2 AI system security vulnerabilities and attacks - Vulnerability (Actors) - Part 1</h1>

        <div class="selection-title">Select a actor:</div>
                <div class="nav-pills">
            <button class="nav-pill active" data-target="AIDeveloperGeneralpurposeAI">
                AI Developer (General-purpose AI)
            </button>
            <button class="nav-pill" data-target="AIDeployer">
                AI Deployer
            </button>
            <button class="nav-pill" data-target="AIGovernanceActor">
                AI Governance Actor
            </button>
            <button class="nav-pill" data-target="AIUser">
                AI User
            </button>
        </div>

                <div class="content-sections">
<div class="entity-section active" id="AIDeveloperGeneralpurposeAI">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Multiple respondents emphasized extreme vulnerability because general-purpose developers are highly exposed to security risks including adversarial attacks, prompt injection, and data leakage. Developers create, configure, and maintain AI models, giving them direct exposure to vulnerabilities like model poisoning, backdoors, or adversarial attacks. They face exposure via training/toolchains, dataset integrity, and signed/attested weights, where compromise propagates downstream.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (3)</summary>
                <ul class="quote-list">
                    <li>"Developers create, configure, and maintain AI models, giving them direct exposure to vulnerabilities such as model poisoning, backdoors, or adversarial attacks."</li>                    <li>"AI developers are indeed more vulnerable to adversarial attacks, and (often) likely not large enough to have capacity for security measures."</li>                    <li>"My ratings track where the attack surface and control plane actually live. GP devs (High) are exposed via training/toolchains, dataset integrity, and signed/attested weights; compromise propagates downstream."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Several argued developers have lower vulnerability, noting that for general-purpose AI, impact would be shielded from developers with vulnerability compartmentalized.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"Developers are not that vulnerable - implementation is isolated from delivery"</li>                    <li>"I did not change my reasoning because for general-purpose AI, the impact would still be shielded from the developers. The actual vulnerability would be quite compartmentalized. I do agree with the reasoning provided by those who voted, but come to a different conclusion."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
<div class="entity-section" id="AIDeployer">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> They integrate AI into operational systems, exposing infrastructure, personnel, and customers to attacks like data exfiltration, adversarial manipulation, or denial-of-service. Deployers are prime targets for prompt injection and other attacks.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (4)</summary>
                <ul class="quote-list">
                    <li>"AI governance actors, deployers, and infrastructure providers are increasingly targeted vectors due to their centrality in system operation and their dependence on legacy tools not built on deterministic or clarity-based frameworks. While individual users and affected stakeholders are indeed vulnerable, their exposure is often indirect or downstream. I raised the governance and infrastructure ratings to reflect systemic vulnerability at the communication and integration layers, particularly where local precision exists without global alignment. This lack of clarity between components is a primary vulnerability not accounted for by technical safeguards alone."</li>                    <li>"Deployers integrate AI into operational systems, exposing their infrastructure, personnel, and customers to attacks such as data exfiltration, adversarial manipulation, or denial-of-service."</li>                    <li>"Increased Deployer vulnerability rating one level, accounting for organisations like retailers and the like potentially vulnerable to prompt injection. In general I think the expert median is too high, because each actor has reasons to be reluctant to adopt systems which are known to be prone to these risks, limiting exposure. The downside (sensitivity) is also much less severe (perhaps some financial harm or sensitive data leak) compared with other risks on the survey."</li>                    <li>"My ratings track where the attack surface and control plane actually live. Deployers (Extreme) run the live stack such as models, RAG, agents/plugins, CI/CD, secrets, logging. So they're the prime target for prompt injection, poisoning, artifact swap, key leakage, and supply-chain pivots."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
<div class="entity-section" id="AIGovernanceActor">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Governance actors don't operate AI systems directly but are indirectly exposed through responsibility for enforcement, oversight, and policy. They're increasingly targeted vectors due to centrality in system operation, particularly at communication and integration layers. They're prime targets for influence and deception campaigns. If systems are attacked, governance actors will be first to be held accountable, making them vulnerable.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (4)</summary>
                <ul class="quote-list">
                    <li>"AI governance actors, deployers, and infrastructure providers are increasingly targeted vectors due to their centrality in system operation and their dependence on legacy tools not built on deterministic or clarity-based frameworks. While individual users and affected stakeholders are indeed vulnerable, their exposure is often indirect or downstream. I raised the governance and infrastructure ratings to reflect systemic vulnerability at the communication and integration layers, particularly where local precision exists without global alignment. This lack of clarity between components is a primary vulnerability not accounted for by technical safeguards alone."</li>                    <li>"Regulators are indirectly exposed: they don't operate AI systems directly, but are responsible for enforcement, oversight, and policy."</li>                    <li>"AI governance actors are a prime target for influence and deception campaigns."</li>                    <li>"If the system is attacked, then AI Governance Actors will be the first to be held accountable, so I believe they are extremely vulnerable"</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> One respondent said: "My ratings track where the attack surface and control plane actually live. Deployers (Extreme) run the live stack such as models, RAG, agents/plugins, CI/CD, secrets, logging. Governance actors (Minimal) are targeted by influence, not runtime exploits. "</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"My ratings track where the attack surface and control plane actually live. Deployers (Extreme) run the live stack such as models, RAG, agents/plugins, CI/CD, secrets, logging. Governance actors (Minimal) are targeted by influence, not runtime exploits."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
<div class="entity-section" id="AIUser">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> End users interact with AI systems but usually lack technical expertise to detect or mitigate security risks. Exposure includes personal data leakage, AI-driven fraud, or manipulation (e.g., phishing via AI-generated content).</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"End users interact with AI systems but usually lack technical expertise to detect or mitigate security risks. Exposure includes personal data leakage, AI-driven fraud, or manipulation (e.g., phishing via AI-generated content)."</li>                    <li>"My ratings track where the attack surface and control plane actually live. Users (Moderate) get phished/jailbroken but don't operate systems."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> One respondent argued: "I see that the median expert assesses AI users as "highly vulnerable" to AI system security attacks. I think users are sensitive to this risk, in that they would be harmed. But I don't think they are exposed in the relevant sense. It's the developers and deployers who are exposed. Yes, the consequence of many or most harms ultimately falls on users. But we are asking about the vulnerability to the risk vector, not the harm to the user."</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"I see that the median expert assesses AI users as "highly vulnerable" to AI system security attacks. I think users are sensitive to this risk, in that they would be harmed. But I don't think they are exposed in the relevant sense. It's the developers and deployers who are exposed. Yes, the consequence of many or most harms ultimately falls on users. But we are asking about the vulnerability to the risk vector, not the harm to the user."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIDeveloperSpecializedAI">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> One expert commented: "My ratings track where the attack surface and control plane actually live.  Specialized devs (Extreme) operate in sensitive domains and often double as deployers, so one flaw bites harder. "</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"My ratings track where the attack surface and control plane actually live.  Specialized devs (Extreme) operate in sensitive domains and often double as deployers, so one flaw bites harder."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIDeployer">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> They integrate AI into operational systems, exposing infrastructure, personnel, and customers to attacks like data exfiltration, adversarial manipulation, or denial-of-service. Deployers are prime targets for prompt injection and other attacks.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (4)</summary>
                <ul class="quote-list">
                    <li>"AI governance actors, deployers, and infrastructure providers are increasingly targeted vectors due to their centrality in system operation and their dependence on legacy tools not built on deterministic or clarity-based frameworks. While individual users and affected stakeholders are indeed vulnerable, their exposure is often indirect or downstream. I raised the governance and infrastructure ratings to reflect systemic vulnerability at the communication and integration layers, particularly where local precision exists without global alignment. This lack of clarity between components is a primary vulnerability not accounted for by technical safeguards alone."</li>                    <li>"Deployers integrate AI into operational systems, exposing their infrastructure, personnel, and customers to attacks such as data exfiltration, adversarial manipulation, or denial-of-service."</li>                    <li>"Increased Deployer vulnerability rating one level, accounting for organisations like retailers and the like potentially vulnerable to prompt injection. In general I think the expert median is too high, because each actor has reasons to be reluctant to adopt systems which are known to be prone to these risks, limiting exposure. The downside (sensitivity) is also much less severe (perhaps some financial harm or sensitive data leak) compared with other risks on the survey."</li>                    <li>"My ratings track where the attack surface and control plane actually live. Deployers (Extreme) run the live stack such as models, RAG, agents/plugins, CI/CD, secrets, logging. So they're the prime target for prompt injection, poisoning, artifact swap, key leakage, and supply-chain pivots."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIInfrastructureProvider">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Multiple respondents emphasized high-to-extreme vulnerability because infrastructure providers are critical points in the AI security chain where compromise can lead to widespread disruptions, large-scale attacks, and data loss. Lack of transparency and control over model updates poses systemic risks. They face multi-tenant isolation challenges, snapshot/backup vulnerabilities, and vector stores and observability pipelines that aggregate sensitive inputs. They control access, scalability, and system integrity, and breaches at this level can compromise multiple models and applications. They are increasingly targeted vectors due to centrality in system operation, particularly at communication and integration layers where local precision exists without global alignment.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"AI governance actors, deployers, and infrastructure providers are increasingly targeted vectors due to their centrality in system operation and their dependence on legacy tools not built on deterministic or clarity-based frameworks. While individual users and affected stakeholders are indeed vulnerable, their exposure is often indirect or downstream. I raised the governance and infrastructure ratings to reflect systemic vulnerability at the communication and integration layers, particularly where local precision exists without global alignment. This lack of clarity between components is a primary vulnerability not accounted for by technical safeguards alone."</li>                    <li>"My ratings track where the attack surface and control plane actually live. Infra (High) faces multi-tenant isolation, snapshot/backup, vector stores, and observability pipelines that aggregate sensitive inputs."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Several respondents argued minimal-to-moderate vulnerability, noting that infrastructure providers are likely to have capacity to put security controls and risk mitigations in place. They would often not be the primary target (making them less exposed), nor would attacks impact them as much as developers or users. One didn't understand arguments about their proximity to model weights or exposure to toolchains, aguing these make infrastructure providers responsible (to protect assets under their control) but not vulnerable (they're not sensitive to the harm but to its causes).</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"AI Infrastructure Provider: I don't understand the arguments raised about their proximity to model weights or their exposure to toolchains. This makes them responsible (to protect the assets that are under their control), not vulnerable (they are not sensitive to the harm but to the causes of that harm)."</li>                    <li>"Upon further review, infrastructure providers seem also at least moderately vulnerable, although they are likely to have the capacity to put security controls and risk mitigations against adversarial attacks in place. They would often not be the primary target (which makes them less exposed), nor would such attacks impact them as much as the developers or users of these systems (as opposed to, e.g., leaked API keys or other unauthorized access)."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIUser">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> End users interact with AI systems but usually lack technical expertise to detect or mitigate security risks. Exposure includes personal data leakage, AI-driven fraud, or manipulation (e.g., phishing via AI-generated content).</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"End users interact with AI systems but usually lack technical expertise to detect or mitigate security risks. Exposure includes personal data leakage, AI-driven fraud, or manipulation (e.g., phishing via AI-generated content)."</li>                    <li>"My ratings track where the attack surface and control plane actually live. Users (Moderate) get phished/jailbroken but don't operate systems."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> One respondent argued: "I see that the median expert assesses AI users as "highly vulnerable" to AI system security attacks. I think users are sensitive to this risk, in that they would be harmed. But I don't think they are exposed in the relevant sense. It's the developers and deployers who are exposed. Yes, the consequence of many or most harms ultimately falls on users. But we are asking about the vulnerability to the risk vector, not the harm to the user."</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"I see that the median expert assesses AI users as "highly vulnerable" to AI system security attacks. I think users are sensitive to this risk, in that they would be harmed. But I don't think they are exposed in the relevant sense. It's the developers and deployers who are exposed. Yes, the consequence of many or most harms ultimately falls on users. But we are asking about the vulnerability to the risk vector, not the harm to the user."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AffectedStakeholder">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Respondents emphasized moderate-to-high vulnerability because affected stakeholders (public, employees, customers) may suffer indirect consequences like algorithmic bias, data leaks, or erroneous automated decisions. While they don't control AI systems, impact can be significant. They experience indirect but significant harms including privacy loss, reputational damage, and erosion of digital trust. Although not interacting directly with system architecture, they're materially affected by breaches, insecure integrations, and downstream misuse of compromised models.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"Affected stakeholders are extremely vulnerable because as attackers exploit AI systems, they will be used in attacks against 3rd parties - who are not the AI system users, owners, deployers."</li>                    <li>"My ratings track where the attack surface and control plane actually live. Affected stakeholders (Minimal) bear impacts but aren't on the controls."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIGovernanceActor">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Governance actors don't operate AI systems directly but are indirectly exposed through responsibility for enforcement, oversight, and policy. They're increasingly targeted vectors due to centrality in system operation, particularly at communication and integration layers. They're prime targets for influence and deception campaigns. If systems are attacked, governance actors will be first to be held accountable, making them vulnerable.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (4)</summary>
                <ul class="quote-list">
                    <li>"AI governance actors, deployers, and infrastructure providers are increasingly targeted vectors due to their centrality in system operation and their dependence on legacy tools not built on deterministic or clarity-based frameworks. While individual users and affected stakeholders are indeed vulnerable, their exposure is often indirect or downstream. I raised the governance and infrastructure ratings to reflect systemic vulnerability at the communication and integration layers, particularly where local precision exists without global alignment. This lack of clarity between components is a primary vulnerability not accounted for by technical safeguards alone."</li>                    <li>"Regulators are indirectly exposed: they don't operate AI systems directly, but are responsible for enforcement, oversight, and policy."</li>                    <li>"AI governance actors are a prime target for influence and deception campaigns."</li>                    <li>"If the system is attacked, then AI Governance Actors will be the first to be held accountable, so I believe they are extremely vulnerable"</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> One respondent said: "My ratings track where the attack surface and control plane actually live. Deployers (Extreme) run the live stack such as models, RAG, agents/plugins, CI/CD, secrets, logging. Governance actors (Minimal) are targeted by influence, not runtime exploits. "</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"My ratings track where the attack surface and control plane actually live. Deployers (Extreme) run the live stack such as models, RAG, agents/plugins, CI/CD, secrets, logging. Governance actors (Minimal) are targeted by influence, not runtime exploits."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const pills = document.querySelectorAll('.nav-pill');
            const sections = document.querySelectorAll('.entity-section');

            pills.forEach(pill => {
                pill.addEventListener('click', function() {
                    pills.forEach(p => p.classList.remove('active'));
                    sections.forEach(s => s.classList.remove('active'));

                    this.classList.add('active');

                    const targetId = this.getAttribute('data-target');
                    const targetSection = document.getElementById(targetId);
                    if (targetSection) {
                        targetSection.classList.add('active');
                    }
                });
            });
        });
    </script>
</body>
</html>
