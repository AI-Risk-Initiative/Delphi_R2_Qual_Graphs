<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>7.1 AI pursuing its own goals in conflict with human goals or values - Vulnerability (Actors) - Part 1</title>
    <link href="https://fonts.googleapis.com/css2?family=Figtree:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Figtree', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            background-color: #ffffff;
            color: #000000;
            line-height: 1.3;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;
        }

        h1 {
            text-align: center;
            margin-bottom: 8px;
            color: #000000;
            font-weight: 600;
            font-size: 18px;
        }

        .selection-title {
            text-align: center;
            font-size: 14px;
            font-weight: 600;
            color: #666666;
            margin-bottom: 10px;
        }

        .nav-pills {
            display: flex;
            flex-wrap: wrap;
            gap: 4px;
            margin-bottom: 15px;
            justify-content: center;
        }

        .nav-pill {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 25px;
            padding: 12px 20px;
            cursor: pointer;
            font-family: 'Figtree', sans-serif;
            font-size: 16px;
            font-weight: 500;
            transition: all 0.3s ease;
            color: #000000;
        }

        .nav-pill:hover {
            background: #e9ecef;
            border-color: #000000;
        }

        .nav-pill.active {
            background: #000000;
            color: white;
            border-color: #000000;
        }

        .entity-section {
            display: none;
        }

        .entity-section.active {
            display: block;
        }

        .content-grid {
            display: flex;
            width: 100%;
            gap: 4px;
        }

        .content-column {
            background: #ffffff;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 8px;
            flex: 1;
            min-width: 200px;
            overflow-wrap: break-word;
            word-break: break-word;
        }

        .criteria-header {
            font-size: 12px;
            font-weight: 600;
            margin-bottom: 15px;
            padding-bottom: 10px;
            border-bottom: 2px solid;
        }

        .criteria-header.higher {
            color: #FF0000;
            border-bottom-color: #FF0000;
        }

        .criteria-header.lower {
            color: #2E5C8A;
            border-bottom-color: #2E5C8A;
        }

        .summary-section {
            margin-bottom: 20px;
        }

        .summary-text {
            margin-bottom: 15px;
            font-weight: 500;
            color: #000000;
            font-size: 15px;
        }

        .quote-details {
            margin-top: 15px;
        }

        .quote-toggle {
            cursor: pointer;
            color: #000000;
            font-weight: 500;
            font-size: 16px;
            background-color: #ffff00;
            padding: 10px 15px;
            border-radius: 4px;
            display: inline-block;
        }

        .quote-toggle:hover {
            color: #333333;
        }

        .quote-list {
            margin-top: 15px;
            padding-left: 20px;
        }

        .quote-list li {
            margin-bottom: 12px;
            font-size: 16px;
            padding: 10px 15px;
            line-height: 1.3;
            color: #000000;
        }

        @media (max-width: 768px) {
            .content-grid {
                gap: 4px;
            }

            .selection-title {
                text-align: center;
                font-size: 14px;
                font-weight: 600;
                color: #666666;
                margin-bottom: 10px;
            }

            .nav-pills {
                justify-content: flex-start;
            }

            .nav-pill {
                font-size: 16px;
                padding: 4px 8px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>7.1 AI pursuing its own goals in conflict with human goals or values - Vulnerability (Actors) - Part 1</h1>

        <div class="selection-title">Select a actor:</div>
                <div class="nav-pills">
            <button class="nav-pill active" data-target="AIDeveloperGeneralpurposeAI">
                AI Developer (General-purpose AI)
            </button>
            <button class="nav-pill" data-target="AIDeployer">
                AI Deployer
            </button>
            <button class="nav-pill" data-target="AIGovernanceActor">
                AI Governance Actor
            </button>
            <button class="nav-pill" data-target="AIUser">
                AI User
            </button>
        </div>

                <div class="content-sections">
<div class="entity-section active" id="AIDeveloperGeneralpurposeAI">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> General-purpose AI developers have high vulnerability to AI misalignment and loss-of-control risks, particularly from internal deployment of frontier AI for ML engineering assistance without safety requirements, which seems like the biggest source of risk exposure and sensitivity. Specialized and general-purpose AI developers are similarly vulnerable to misalignment due to the underlying training process they share. Some experts updated their view that GPAI developers might have slightly more influence than other sectors.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (3)</summary>
                <ul class="quote-list">
                    <li>"I think that GPAI developers have the highest vulnerability to AI misalignment and loss-of-control risks, because internal deployment of frontier AI for ML engineering assistance (without any safety requirements) seems like the biggest source of risk exposure and sensitivity."</li>                    <li>"Specialized and general-purpose AI developers are similarly vulnerable to misalignment due to the underlying training process they share"</li>                    <li>"Updated in light of the argument that GPAI developers might have slightly more influence than other sectors, though there's not much in it in my view."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> One expert argued general-purpose AI developers are not in a vulnerable position since they are essentially backed by governments now.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"I wouldnt say the gen-purp AI devs are at a vulnerable position since they are essentially backed by governments now."</li>                    <li>"I disagree with the comment on low vulnerability for GPAI developers. Their argument was around control. 
My reasoning here is that the developer would "feel" the harms minimally -- i.e. low sensitivity.
That same argument applies for specialized developers.
But not for deployers, who I think of as the actor that controls and is thus most affected by the actions of the AI system."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
<div class="entity-section" id="AIDeployer">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Deployers are the actors who control and are thus most affected by the actions of AI systems. Some experts updated their vulnerability assessments for deployers to a higher level of risk, noting that use of AI agents to assist with programming and writing is more likely than previously considered, increasing both risk exposure and sensitivity.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"I disagree with the commented on low vulnerability for GPAI developers. Their argument was around control. 
My reasoning here is that the developer would "feel" the harms minimally -- i.e. low sensitivity.
That same argument applies for specialized developers.
But not for deployers, who I think of as the actor that controls and is thus most affected by the actions of the AI system."</li>                    <li>"Relative to round 1, I have updated my vulnerability assessments for AI deployers and governance actors to a higher level of risk; after reflecting on the median assessments for these categories, I think the use of AI agents to assist with programming and writing is more likely than I previously considered, and that increases both the risk exposure and sensitivity."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
<div class="entity-section" id="AIGovernanceActor">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Only one expert commented: "Relative to round 1, I have updated my vulnerability assessments for AI deployers and governance actors to a higher level of risk; after reflecting on the median assessments for these categories, I think the use of AI agents to assist with programming and writing is more likely than I previously considered, and that increases both the risk exposure and sensitivity."</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"Relative to round 1, I have updated my vulnerability assessments for AI deployers and governance actors to a higher level of risk; after reflecting on the median assessments for these categories, I think the use of AI agents to assist with programming and writing is more likely than I previously considered, and that increases both the risk exposure and sensitivity."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
<div class="entity-section" id="AIUser">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Experts argue AI users are extremely vulnerable to reflect exposure to systemic failure, not due to lack of agency—users are still cognitively capable and must be supported structurally, being highly at risk without systemic safeguards. This risk concerns AIs pursuing their own goals in conflict with human goals, and humans here would be those who use AIs. Other AI ecosystem actors play different roles in the value chain, but if people in these roles are affected, they are primarily affected as AI users.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"I updated "AI User" to extremely vulnerable to reflect the exposure to systemic failure, not due to lack of agency. From a clarity and calibration lens, users are still cognitively capable and must be supported structurally. They are highly at risk without systemic safeguards."</li>                    <li>"This risk concerns AIs pursuing its own goals in conflict with human goals, and humans here would be those who use AIs i.e. AI users. The other AI ecosystem actors e.g. developers, deployers, governance actors, play different roles in the value chain. If people involved in these actors are affected, they are primarily affected as AI users."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIDeveloperSpecializedAI">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Specialized and general-purpose AI developers are similarly vulnerable to misalignment due to the underlying training process they share.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"Specialized and general-purpose AI developers are similarly vulnerable to misalignment due to the underlying training process they share"</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Multiple experts noted specialized AI systems are unlikely to develop their own goals in conflict with humans due to their inherently narrow domain. Specialized AI has less explicit vulnerability since they are not necessarily using classes of systems that can rebel.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (3)</summary>
                <ul class="quote-list">
                    <li>"I disagree with the commented on low vulnerability for GPAI developers. Their argument was around control. 
My reasoning here is that the developer would "feel" the harms minimally -- i.e. low sensitivity.
That same argument applies for specialized developers.
But not for deployers, who I think of as the actor that controls and is thus most affected by the actions of the AI system."</li>                    <li>"Specialized AI systems are, on average, highly unlikely to develop their own goals in conflict with humans due to the inherently narrow domain (excluding bias/misperformance failures).  I'm unsure why experts rated specialized AI developers to be highly vulnerable."</li>                    <li>"Specialized AI has less explicit vulnerability to their systems, since they are not (necessarily) using classes of systems that can rebel."</li>
                </ul>
            </details>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIDeployer">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Deployers are the actors who control and are thus most affected by the actions of AI systems. Some experts updated their vulnerability assessments for deployers to a higher level of risk, noting that use of AI agents to assist with programming and writing is more likely than previously considered, increasing both risk exposure and sensitivity.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"I disagree with the commented on low vulnerability for GPAI developers. Their argument was around control. 
My reasoning here is that the developer would "feel" the harms minimally -- i.e. low sensitivity.
That same argument applies for specialized developers.
But not for deployers, who I think of as the actor that controls and is thus most affected by the actions of the AI system."</li>                    <li>"Relative to round 1, I have updated my vulnerability assessments for AI deployers and governance actors to a higher level of risk; after reflecting on the median assessments for these categories, I think the use of AI agents to assist with programming and writing is more likely than I previously considered, and that increases both the risk exposure and sensitivity."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIInfrastructureProvider">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Infrastructure providers are extremely vulnerable as access to compute and control of AI infrastructure is one of the most important objectives for misaligned AI, with extreme exposure making them a likely main target. If a misaligned AI tries to escape containment and acquire power/resources, computing hardware is one of the most likely things it will attempt to seize control of. Gaining control of compute resources would give an AI system a significant advantage in increasing its capabilities to pursue its own goals.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (3)</summary>
                <ul class="quote-list">
                    <li>"Access to compute and control of AI infrastructure is one of the most important objectives for misaligned AI. Infrastructure providers have extreme exposure to AI systems and are likely to be a main target."</li>                    <li>"AI infrastructure providers are the most vulnerable of all. If a misaligned AI tries to escape containment and acquire power/resources, computing hardware is one of the most likely things it will attempt to seize control of."</li>                    <li>"AI infrastructure provider is extremely vulnerable because of the great extent that the most advanced AI models will be interacting with infrastructure (exposure), and the fact that gaining control of compute resources would give an AI system such an advantage in increasing its capabilities to pursue its own goals."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIUser">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Experts argue AI users are extremely vulnerable to reflect exposure to systemic failure, not due to lack of agency—users are still cognitively capable and must be supported structurally, being highly at risk without systemic safeguards. This risk concerns AIs pursuing their own goals in conflict with human goals, and humans here would be those who use AIs. Other AI ecosystem actors play different roles in the value chain, but if people in these roles are affected, they are primarily affected as AI users.</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (2)</summary>
                <ul class="quote-list">
                    <li>"I updated "AI User" to extremely vulnerable to reflect the exposure to systemic failure, not due to lack of agency. From a clarity and calibration lens, users are still cognitively capable and must be supported structurally. They are highly at risk without systemic safeguards."</li>                    <li>"This risk concerns AIs pursuing its own goals in conflict with human goals, and humans here would be those who use AIs i.e. AI users. The other AI ecosystem actors e.g. developers, deployers, governance actors, play different roles in the value chain. If people involved in these actors are affected, they are primarily affected as AI users."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AffectedStakeholder">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
            <div class="entity-section" id="AIGovernanceActor">
                <div class="content-grid">
                    <div class="content-column">
                        <h3 class="criteria-header higher">Reasons for Higher Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> Only one expert commented: "Relative to round 1, I have updated my vulnerability assessments for AI deployers and governance actors to a higher level of risk; after reflecting on the median assessments for these categories, I think the use of AI agents to assist with programming and writing is more likely than I previously considered, and that increases both the risk exposure and sensitivity."</p>

            <details class="quote-details">
                <summary class="quote-toggle">See all expert comments (1)</summary>
                <ul class="quote-list">
                    <li>"Relative to round 1, I have updated my vulnerability assessments for AI deployers and governance actors to a higher level of risk; after reflecting on the median assessments for these categories, I think the use of AI agents to assist with programming and writing is more likely than I previously considered, and that increases both the risk exposure and sensitivity."</li>
                </ul>
            </details>
                        </div>
                    </div>
                    <div class="content-column">
                        <h3 class="criteria-header lower">Reasons for Lower Vulnerability</h3>
                        <div class="summary-section">
                            <p class="summary-text"><strong>AI-generated summary of expert comments:</strong> [NO EXPERT COMMENTS PROVIDED]</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const pills = document.querySelectorAll('.nav-pill');
            const sections = document.querySelectorAll('.entity-section');

            pills.forEach(pill => {
                pill.addEventListener('click', function() {
                    pills.forEach(p => p.classList.remove('active'));
                    sections.forEach(s => s.classList.remove('active'));

                    this.classList.add('active');

                    const targetId = this.getAttribute('data-target');
                    const targetSection = document.getElementById(targetId);
                    if (targetSection) {
                        targetSection.classList.add('active');
                    }
                });
            });
        });
    </script>
</body>
</html>
